# Fine-Tuning Datasets for GPT-4.1-Nano

This directory contains four fine-tuning datasets prepared for OpenAI's GPT-4.1-nano model, based on the Clue game prediction task.

## Datasets

### 1. `most-confident-wrong.jsonl` (72 examples)
Test cases where the model was most confident but incorrect.
- Average confidence: 85.1%
- Confidence range: 73.8% - 98.7%
- **Purpose**: Help the model recognize and correct its overconfident errors

### 2. `least-confident-wrong.jsonl` (72 examples)
Test cases where the model had low confidence and was incorrect.
- Average confidence: 5.9%
- Confidence range: 0.1% - 10.8%
- **Purpose**: Help the model improve on cases where it's uncertain

### 3. `correct.jsonl` (72 examples)
Test cases where the model predicted correctly.
- Average confidence: 47.0%
- **Purpose**: Reinforce successful reasoning patterns

### 4. `all-cases.jsonl` (500 examples)
All test cases from the dataset.
- **Purpose**: Comprehensive fine-tuning on the entire task

## Format

Each file is in JSONL format (one JSON object per line), following OpenAI's fine-tuning format:

```json
{
  "messages": [
    {
      "role": "user",
      "content": "# Clue Logic Puzzle\n\nDetermine who the killer is..."
    },
    {
      "role": "assistant",
      "content": "Linda"
    }
  ]
}
```

## Usage

These datasets can be uploaded to OpenAI and used for fine-tuning:

```bash
# First install the OpenAI SDK
pnpm add openai

# Then run the fine-tuning script
pnpm script scripts/submit-fine-tune-jobs.ts
```

**Warning**: Running the fine-tuning script will create actual fine-tuning jobs that will incur costs on your OpenAI account.

## Generated By

- `scripts/generate-fine-tune-datasets.ts` - Generates these JSONL files from predictions
- `scripts/submit-fine-tune-jobs.ts` - Submits fine-tuning jobs to OpenAI (not yet run)
